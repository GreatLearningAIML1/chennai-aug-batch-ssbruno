{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AS data file is in H5 document, using h5py package to read the file\n",
    "f = h5py.File('SVHN_single_grey1.h5', 'r')\n",
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Train and Test data from the file\n",
    "x_train = f.get('X_train')\n",
    "y_train = f.get('y_train')\n",
    "x_test = f.get('X_test')\n",
    "y_test = f.get('y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in Training dataset:  42000\n",
      "Number of samples in Test dataset:  18000\n",
      "Dimensions of the image: (32, 32)\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples in Training dataset: ', x_train.shape[0])\n",
    "print('Number of samples in Test dataset: ', x_test.shape[0])\n",
    "print('Dimensions of the image:', x_train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_lst = []\n",
    "\n",
    "for x in x_train:\n",
    "    x = x.astype('float32')\n",
    "    x /= 255\n",
    "    x_train_lst.append(x.reshape(1024))\n",
    "\n",
    "x_train_df = pd.DataFrame(x_train_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier = KNeighborsClassifier(n_neighbors=5)  \n",
    "classifier.fit(x_train_df, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing Test Data\n",
    "x_test_lst = []\n",
    "\n",
    "for x in x_test:\n",
    "    x = x.astype('float32')\n",
    "    x /= 255\n",
    "    x_test_lst.append(x.reshape(1024))\n",
    "\n",
    "x_test_df = pd.DataFrame(x_test_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test_df.iloc[0:1000,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[77  8  1  2  2  2  8  1  7  9]\n",
      " [ 3 72  4  5  4  1  2  2  0  0]\n",
      " [10 18 41  5  1  1  2  4  4  6]\n",
      " [ 9 10 10 36  2  6  3  1  3  5]\n",
      " [11 14  3  2 58  1  2  2  2  1]\n",
      " [11 12  3 15  3 41  5  1  6  8]\n",
      " [13  7  2  2 13 10 38  0  7  2]\n",
      " [ 6 16  7  1  1  1  0 71  1  3]\n",
      " [22  9  4  3  3  6  8  2 39  4]\n",
      " [20  8  5  8  5  4  7  4 10 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.66      0.52       117\n",
      "           1       0.41      0.77      0.54        93\n",
      "           2       0.51      0.45      0.48        92\n",
      "           3       0.46      0.42      0.44        85\n",
      "           4       0.63      0.60      0.62        96\n",
      "           5       0.56      0.39      0.46       105\n",
      "           6       0.51      0.40      0.45        94\n",
      "           7       0.81      0.66      0.73       107\n",
      "           8       0.49      0.39      0.44       100\n",
      "           9       0.51      0.36      0.42       111\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      1000\n",
      "   macro avg       0.53      0.51      0.51      1000\n",
      "weighted avg       0.53      0.51      0.51      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test[0:1000,], y_pred))\n",
    "print(classification_report(y_test[0:1000,], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With KNN the prediction accuracy was between 50-60%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_nn = x_train.value\n",
    "x_test_nn = x_test.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_nn = x_train_nn.astype('float32')\n",
    "x_test_nn = x_test_nn.astype('float32')\n",
    "\n",
    "x_train_nn /= 255\n",
    "x_test_nn /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_nn = x_train_nn.reshape(x_train_nn.shape[0], 32, 32, 1).astype('float32')\n",
    "x_test_nn = x_test_nn.reshape(x_test_nn.shape[0], 32, 32, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing a Deep Neural Network Classifier with\n",
    "1. RELU Activations\n",
    "2. Batch Normalisation\n",
    "3. Cost Functions\n",
    "4. Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\AIML\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=10, kernel_initializer=\"he_normal\", use_bias=True)`\n",
      "C:\\Users\\ssbru\\AppData\\Roaming\\Python\\Python36\\site-packages\\h5py\\_hl\\dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/10\n",
      "42000/42000 [==============================] - 212s 5ms/step - loss: 0.9241 - acc: 0.7117 - val_loss: 0.6330 - val_acc: 0.8059\n",
      "Epoch 2/10\n",
      "42000/42000 [==============================] - 207s 5ms/step - loss: 0.5324 - acc: 0.8368 - val_loss: 0.5124 - val_acc: 0.8456\n",
      "Epoch 3/10\n",
      "42000/42000 [==============================] - 181s 4ms/step - loss: 0.4432 - acc: 0.8648 - val_loss: 0.5657 - val_acc: 0.8260\n",
      "Epoch 4/10\n",
      "42000/42000 [==============================] - 181s 4ms/step - loss: 0.3757 - acc: 0.8822 - val_loss: 0.4549 - val_acc: 0.8697\n",
      "Epoch 5/10\n",
      "42000/42000 [==============================] - 181s 4ms/step - loss: 0.3306 - acc: 0.8955 - val_loss: 0.5295 - val_acc: 0.8505\n",
      "Epoch 6/10\n",
      "42000/42000 [==============================] - 187s 4ms/step - loss: 0.2942 - acc: 0.9080 - val_loss: 0.4885 - val_acc: 0.8644\n",
      "Epoch 7/10\n",
      "42000/42000 [==============================] - 184s 4ms/step - loss: 0.2579 - acc: 0.9182 - val_loss: 0.5372 - val_acc: 0.8488\n",
      "Epoch 8/10\n",
      "42000/42000 [==============================] - 181s 4ms/step - loss: 0.2344 - acc: 0.9262 - val_loss: 0.4950 - val_acc: 0.8653\n",
      "Epoch 9/10\n",
      "42000/42000 [==============================] - 180s 4ms/step - loss: 0.2053 - acc: 0.9344 - val_loss: 0.5459 - val_acc: 0.8604\n",
      "Epoch 00009: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f80258a7b8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Conv Layer\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 1)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 2nd Conv Layer\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Fully Connected Layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Batch Normalisation\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "# Prediction Layer\n",
    "model.add(Dense(output_dim=10, init='he_normal', bias=True))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Loss and Optimizer\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "# Store Training Results\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n",
    "callback_list = [early_stopping]\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_nn, y_train.value, batch_size=32, epochs=10,\n",
    "           validation_data=(x_test_nn, y_test.value), callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nn = model.predict(x_test_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  7\n",
       "2  2\n",
       "3  9\n",
       "4  0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lst = np.argmax(y_pred_nn, axis=1)\n",
    "y_pred_df = pd.DataFrame(y_pred_lst)\n",
    "y_pred_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1694   17    7    7   12    4   24    9   15   25]\n",
      " [  69 1579   11   28   64   12   10   17   23   15]\n",
      " [  26    7 1566   36   39    7    5   30   24   63]\n",
      " [  25   20   13 1402   19  125   20    9   56   30]\n",
      " [  19   40   13   24 1616   14   23    8   22   33]\n",
      " [  13   13    8   79   12 1517   63   11   28   24]\n",
      " [  60   16    7   31   24   61 1543    1   69   20]\n",
      " [  51   64   44   41   16   20   14 1535    9   14]\n",
      " [  35   25    9   58   23   41   67    5 1505   44]\n",
      " [  76   27   19   39   16   38   16   12   31 1530]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      1814\n",
      "           1       0.87      0.86      0.87      1828\n",
      "           2       0.92      0.87      0.89      1803\n",
      "           3       0.80      0.82      0.81      1719\n",
      "           4       0.88      0.89      0.88      1812\n",
      "           5       0.82      0.86      0.84      1768\n",
      "           6       0.86      0.84      0.85      1832\n",
      "           7       0.94      0.85      0.89      1808\n",
      "           8       0.84      0.83      0.84      1812\n",
      "           9       0.85      0.85      0.85      1804\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     18000\n",
      "   macro avg       0.86      0.86      0.86     18000\n",
      "weighted avg       0.86      0.86      0.86     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_df))  \n",
    "print(classification_report(y_test, y_pred_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy of KNN ML: 50-60%\n",
    "##### Accuracy of DL ML: 86%\n",
    "\n",
    "##### Image classification is better done by Deep Learning model \n",
    "\n",
    "Accuracy of Deep Learning Model was approximately 30% higher than Traditional Machine Learning (KNN) model.\n",
    "KNN model computation took longer than Deep Learning computations. \n",
    "As we run DL model in batches of data, in the first epoch itself we could see the accuracy and loss and hot the model performs.\n",
    "As we can not do feature analysis on pixel values, we can not improve the efficiency and accuracy of the KNN model.\n",
    "DL perfroms better in places where the EDL is not easily possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
